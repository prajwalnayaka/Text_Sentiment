{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAVuCZukFE60",
    "outputId": "0700d51f-22fb-4f10-dc21-c34dcb3bb9e9",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:03.979971Z",
     "start_time": "2025-11-16T07:09:02.467651Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "from transformers import DistilBertForSequenceClassification, TrainingArguments"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing dataset"
  },
  {
   "cell_type": "code",
   "source": [
    "ds=pd.read_csv(r\"D:\\Text_Sentiment\\final_dataset_v4.csv\")\n",
    "print(ds.shape)\n",
    "print(ds.columns)\n",
    "print(ds['emotion'].value_counts())\n",
    "ds.dropna(inplace=True)\n",
    "print(ds.isnull().sum())\n",
    "print(len(ds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhiY-6GqIQx8",
    "outputId": "a57244a2-1556-4838-e927-e1f3f8b3b756",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:04.124341Z",
     "start_time": "2025-11-16T07:09:03.985492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106344, 3)\n",
      "Index(['text', 'emotion', 'labels'], dtype='object')\n",
      "emotion\n",
      "neutral       10059\n",
      "enthusiasm    10044\n",
      "fun           10033\n",
      "love          10023\n",
      "relief        10020\n",
      "anger         10020\n",
      "hate          10006\n",
      "sadness        9987\n",
      "happiness      9904\n",
      "surprise       9880\n",
      "empty          6368\n",
      "Name: count, dtype: int64\n",
      "text       0\n",
      "emotion    0\n",
      "labels     0\n",
      "dtype: int64\n",
      "106344\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating an emotion -> integer mapping column called 'labels'"
  },
  {
   "cell_type": "code",
   "source": [
    "emotions=ds['emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "mapping={label: i for i, label in enumerate(emotions)}\n",
    "ds['labels'] = ds['emotion'].map(mapping)"
   ],
   "metadata": {
    "id": "NjxmAzx4I72Z",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:04.140999Z",
     "start_time": "2025-11-16T07:09:04.129561Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun', 'surprise', 'neutral', 'enthusiasm', 'happiness', 'hate', 'sadness', 'empty', 'love', 'relief', 'anger']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(ds['text']))\n",
    "print(len(ds['emotion']))\n",
    "print(len(ds['labels']))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cr5M8byAsEH6",
    "outputId": "9b2e30fd-0478-4966-91c3-9f281d86dce9",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:04.176747Z",
     "start_time": "2025-11-16T07:09:04.173780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106344\n",
      "106344\n",
      "106344\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Splitting dataset into train, test and validation sets"
  },
  {
   "cell_type": "code",
   "source": [
    "X=ds['text']\n",
    "y=ds['labels']\n",
    "X_train,X_temp,y_train,y_temp=train_test_split(X,y,test_size=0.2,stratify=y,random_state=1) #stratify based on target (y) for a homogenous and unbiased sets\n",
    "X_val, X_test, y_val, y_test=train_test_split(X_temp,y_temp,test_size=0.5,stratify=y_temp,random_state=1) #splitting the remaining 0.3 into 50% test and 50% val\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fbaGNgkLUkm",
    "outputId": "1bb32a43-dfae-4e53-f918-e32694c610a1",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:04.758569Z",
     "start_time": "2025-11-16T07:09:04.188556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 85075\n",
      "Testing set size: 10635\n",
      "Validation set size: 10634\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using DistilBERT's specific tokenizer to create a embeddings of the features (X)"
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer=DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "sample_text = X_train.iloc[0]\n",
    "sample_encoding = tokenizer(sample_text, return_tensors='pt')\n",
    "print(sample_text)\n",
    "print(sample_encoding)\n",
    "print(f\"Decoded Text: {tokenizer.decode(sample_encoding['input_ids'][0])}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_labels = torch.tensor(y_train.tolist())\n",
    "val_labels = torch.tensor(y_val.tolist())\n",
    "test_labels = torch.tensor(y_test.tolist())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XW5SlW2KnrLD",
    "outputId": "c73df50d-3f0a-4324-fb12-d527d629133f",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:15.422268Z",
     "start_time": "2025-11-16T07:09:04.770502Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13400f_RTX4060ti\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i didnt feel as excited having unfortunately\n",
      "{'input_ids': tensor([[ 101, 1045, 2134, 2102, 2514, 2004, 7568, 2383, 6854,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Decoded Text: [CLS] i didnt feel as excited having unfortunately [SEP]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating a custom PyTorch dataset class"
  },
  {
   "cell_type": "code",
   "source": [
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset class to interface the tokenized inputs\n",
    "    and integer labels for the Hugging Face Trainer.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "train_dataset = EmotionDataset(train_encodings, train_labels) #Creating objects of EmotionDataset class for the train dataset\n",
    "val_dataset = EmotionDataset(val_encodings, val_labels) #Creating objects of EmotionDataset class for the val dataset\n",
    "test_dataset = EmotionDataset(test_encodings, test_labels) #Creating objects of EmotionDataset class for the test dataset\n",
    "\n",
    "print(\"PyTorch Dataset objects created successfully.\")"
   ],
   "metadata": {
    "id": "QpKdEVVc3b_b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed70a312-949d-4750-c515-a9ff65c8beae",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:15.499049Z",
     "start_time": "2025-11-16T07:09:15.494567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Dataset objects created successfully.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing the model and training hyperparameters (training_args)"
  },
  {
   "cell_type": "code",
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=len(emotions))\n",
    "model.to(device)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./emotion_results',  # Directory to save model checkpoints\n",
    "    num_train_epochs=3,              # Number of times to run through the entire training set (Adjust if needed)\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=16,  # Training batch size (Adjust if you run out of GPU memory)\n",
    "    per_device_eval_batch_size=64,   # Evaluation batch size (can be larger than training batch size)\n",
    "    warmup_steps=500,                # Learning rate scheduler warm-up steps\n",
    "    weight_decay=0.01,               # L2 regularization\n",
    "    logging_dir='./emotion_logs',    # Directory for logs\n",
    "    logging_steps=100,               # Log training status every 100 steps\n",
    "    save_strategy=\"epoch\",     # Save best model version after each epoch\n",
    "    eval_strategy=\"epoch\",     # Run evaluation on the validation set after every epoch\n",
    "    load_best_model_at_end=True,     # Save the model that performs best on the validation set\n",
    "    fp16=True,                       # Enables faster 16-bit precision training (requires GPU)\n",
    "    report_to=\"none\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcpxFjEMaO8q",
    "outputId": "87d2221d-ed30-4cb9-d09b-2d97d56ede8b",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:16.834457Z",
     "start_time": "2025-11-16T07:09:15.508232Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculating the performance metrics"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "num_emotions=len(emotions)\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Computes accuracy, weighted F1, and per-class precision (to check specific emotions).\n",
    "    \"\"\"\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    class_metrics = precision_recall_fscore_support(p.label_ids, preds, average=None, labels=range(num_emotions), zero_division=0)\n",
    "    class_precision = class_metrics[0]\n",
    "    precision_by_class = {emotions[i]: class_precision[i] for i in range(num_emotions)}\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        **{f'precision_{k}': v for k, v in precision_by_class.items()}, # Adds individual precision scores\n",
    "    }"
   ],
   "metadata": {
    "id": "6mDlX9jlltgW",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:16.856350Z",
     "start_time": "2025-11-16T07:09:16.853249Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing a trainer object from Hugging Face Trainer class"
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(\"Hugging Face Trainer initialized successfully.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5suU4meqLyr",
    "outputId": "5e4bfc7c-f382-4ba5-a239-15bc03eb35a1",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:09:16.919923Z",
     "start_time": "2025-11-16T07:09:16.861825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face Trainer initialized successfully.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the model"
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()\n",
    "final_results=trainer.evaluate(test_dataset)\n",
    "print(final_results)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "j-Ls70fvsSAV",
    "outputId": "74c2f9a0-bbb6-4410-e06a-8fd432b81037",
    "ExecuteTime": {
     "end_time": "2025-11-16T07:21:15.862200Z",
     "start_time": "2025-11-16T07:09:16.932249Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15954' max='15954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15954/15954 11:52, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision Fun</th>\n",
       "      <th>Precision Surprise</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Precision Enthusiasm</th>\n",
       "      <th>Precision Happiness</th>\n",
       "      <th>Precision Hate</th>\n",
       "      <th>Precision Sadness</th>\n",
       "      <th>Precision Empty</th>\n",
       "      <th>Precision Love</th>\n",
       "      <th>Precision Relief</th>\n",
       "      <th>Precision Anger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.339400</td>\n",
       "      <td>0.365547</td>\n",
       "      <td>0.886496</td>\n",
       "      <td>0.888705</td>\n",
       "      <td>0.895132</td>\n",
       "      <td>0.886496</td>\n",
       "      <td>0.900407</td>\n",
       "      <td>0.829099</td>\n",
       "      <td>0.955078</td>\n",
       "      <td>0.971875</td>\n",
       "      <td>0.790607</td>\n",
       "      <td>0.989236</td>\n",
       "      <td>0.650456</td>\n",
       "      <td>0.985689</td>\n",
       "      <td>0.944332</td>\n",
       "      <td>0.963880</td>\n",
       "      <td>0.895772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.891010</td>\n",
       "      <td>0.893589</td>\n",
       "      <td>0.898521</td>\n",
       "      <td>0.891010</td>\n",
       "      <td>0.946272</td>\n",
       "      <td>0.713393</td>\n",
       "      <td>0.978852</td>\n",
       "      <td>0.990426</td>\n",
       "      <td>0.787996</td>\n",
       "      <td>0.982942</td>\n",
       "      <td>0.709059</td>\n",
       "      <td>0.967298</td>\n",
       "      <td>0.952333</td>\n",
       "      <td>0.957055</td>\n",
       "      <td>0.918408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.239600</td>\n",
       "      <td>0.404647</td>\n",
       "      <td>0.890916</td>\n",
       "      <td>0.892128</td>\n",
       "      <td>0.894152</td>\n",
       "      <td>0.890916</td>\n",
       "      <td>0.892167</td>\n",
       "      <td>0.783976</td>\n",
       "      <td>0.980847</td>\n",
       "      <td>0.962887</td>\n",
       "      <td>0.793510</td>\n",
       "      <td>0.966736</td>\n",
       "      <td>0.716563</td>\n",
       "      <td>0.938538</td>\n",
       "      <td>0.954361</td>\n",
       "      <td>0.942656</td>\n",
       "      <td>0.916091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [167/167 00:05]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.34344935417175293, 'eval_accuracy': 0.8905500705218617, 'eval_f1': 0.8926634528942966, 'eval_precision': 0.8964495193028569, 'eval_recall': 0.8905500705218617, 'eval_precision_fun': 0.9416846652267818, 'eval_precision_surprise': 0.7215756490599821, 'eval_precision_neutral': 0.9761431411530815, 'eval_precision_enthusiasm': 0.9904559915164369, 'eval_precision_happiness': 0.7869012707722385, 'eval_precision_hate': 0.9706806282722513, 'eval_precision_sadness': 0.718552036199095, 'eval_precision_empty': 0.9599332220367279, 'eval_precision_love': 0.9512195121951219, 'eval_precision_relief': 0.9422084623323014, 'eval_precision_anger': 0.9196428571428571, 'eval_runtime': 5.9315, 'eval_samples_per_second': 1792.984, 'eval_steps_per_second': 28.155, 'epoch': 3.0}\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ]
}
