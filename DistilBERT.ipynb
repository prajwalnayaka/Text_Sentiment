{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing libraries"
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hAVuCZukFE60",
    "outputId": "0700d51f-22fb-4f10-dc21-c34dcb3bb9e9",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:28:52.169300Z",
     "start_time": "2025-11-21T07:28:33.095551Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.get_device_name(0))\n",
    "from transformers import DistilBertForSequenceClassification, TrainingArguments"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\13400f_RTX4060ti\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "NVIDIA GeForce RTX 4060 Ti\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importing dataset"
  },
  {
   "cell_type": "code",
   "source": [
    "ds=pd.read_csv(r\"D:\\Text_Sentiment\\datasets\\final_dataset.csv\")\n",
    "print(ds.shape)\n",
    "print(ds.columns)\n",
    "print(ds['emotion'].value_counts())\n",
    "ds.dropna(inplace=True)\n",
    "print(ds.isnull().sum())\n",
    "print(len(ds))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AhiY-6GqIQx8",
    "outputId": "a57244a2-1556-4838-e927-e1f3f8b3b756",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:28:52.321550Z",
     "start_time": "2025-11-21T07:28:52.176722Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106355, 2)\n",
      "Index(['text', 'emotion'], dtype='object')\n",
      "emotion\n",
      "fun           10000\n",
      "surprise      10000\n",
      "enthusiasm    10000\n",
      "anger         10000\n",
      "happiness     10000\n",
      "hate          10000\n",
      "love          10000\n",
      "relief        10000\n",
      "sadness        9999\n",
      "neutral        9998\n",
      "empty          6358\n",
      "Name: count, dtype: int64\n",
      "text       0\n",
      "emotion    0\n",
      "dtype: int64\n",
      "106355\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating an emotion -> integer mapping column called 'labels'"
  },
  {
   "cell_type": "code",
   "source": [
    "emotions=ds['emotion'].unique().tolist()\n",
    "print(emotions)\n",
    "mapping={label: i for i, label in enumerate(emotions)}\n",
    "ds['labels'] = ds['emotion'].map(mapping)"
   ],
   "metadata": {
    "id": "NjxmAzx4I72Z",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:28:52.340899Z",
     "start_time": "2025-11-21T07:28:52.328181Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fun', 'surprise', 'neutral', 'enthusiasm', 'happiness', 'hate', 'sadness', 'empty', 'love', 'relief', 'anger']\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "print(len(ds['text']))\n",
    "print(len(ds['emotion']))\n",
    "print(len(ds['labels']))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cr5M8byAsEH6",
    "outputId": "9b2e30fd-0478-4966-91c3-9f281d86dce9",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:28:52.374680Z",
     "start_time": "2025-11-21T07:28:52.371259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106355\n",
      "106355\n",
      "106355\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Splitting dataset into train, test and validation sets"
  },
  {
   "cell_type": "code",
   "source": [
    "X=ds['text']\n",
    "y=ds['labels']\n",
    "X_train,X_temp,y_train,y_temp=train_test_split(X,y,test_size=0.2,stratify=y,random_state=1) #stratify based on target (y) for a homogenous and unbiased sets\n",
    "X_val, X_test, y_val, y_test=train_test_split(X_temp,y_temp,test_size=0.5,stratify=y_temp,random_state=1) #splitting the remaining 0.3 into 50% test and 50% val\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Testing set size: {len(X_test)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1fbaGNgkLUkm",
    "outputId": "1bb32a43-dfae-4e53-f918-e32694c610a1",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:28:52.423857Z",
     "start_time": "2025-11-21T07:28:52.383163Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 85084\n",
      "Testing set size: 10636\n",
      "Validation set size: 10635\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Using DistilBERT's specific tokenizer to create a embeddings of the features (X)"
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer=DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(X_train.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "val_encodings = tokenizer(X_val.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "test_encodings = tokenizer(X_test.tolist(), truncation=True, padding=True, return_tensors='pt')\n",
    "sample_text = X_train.iloc[0]\n",
    "sample_encoding = tokenizer(sample_text, return_tensors='pt')\n",
    "print(sample_text)\n",
    "print(sample_encoding)\n",
    "print(f\"Decoded Text: {tokenizer.decode(sample_encoding['input_ids'][0])}\")\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_labels = torch.tensor(y_train.tolist())\n",
    "val_labels = torch.tensor(y_val.tolist())\n",
    "test_labels = torch.tensor(y_test.tolist())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XW5SlW2KnrLD",
    "outputId": "c73df50d-3f0a-4324-fb12-d527d629133f",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:29:01.264373Z",
     "start_time": "2025-11-21T07:28:52.445013Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faced a major today. My first time on the bike to office. whew\n",
      "{'input_ids': tensor([[ 101, 4320, 1037, 2350, 2651, 1012, 2026, 2034, 2051, 2006, 1996, 7997,\n",
      "         2000, 2436, 1012, 1059, 5369, 2860,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "Decoded Text: [CLS] faced a major today. my first time on the bike to office. whew [SEP]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Creating a custom PyTorch dataset class"
  },
  {
   "cell_type": "code",
   "source": [
    "class EmotionDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset class to interface the tokenized inputs\n",
    "    and integer labels for the Hugging Face Trainer.\n",
    "    \"\"\"\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx].clone().detach() for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx].clone().detach()\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "train_dataset = EmotionDataset(train_encodings, train_labels) #Creating objects of EmotionDataset class for the train dataset\n",
    "val_dataset = EmotionDataset(val_encodings, val_labels) #Creating objects of EmotionDataset class for the val dataset\n",
    "test_dataset = EmotionDataset(test_encodings, test_labels) #Creating objects of EmotionDataset class for the test dataset\n",
    "\n",
    "print(\"PyTorch Dataset objects created successfully.\")"
   ],
   "metadata": {
    "id": "QpKdEVVc3b_b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed70a312-949d-4750-c515-a9ff65c8beae",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:29:01.478727Z",
     "start_time": "2025-11-21T07:29:01.474698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Dataset objects created successfully.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing the model and training hyperparameters (training_args)"
  },
  {
   "cell_type": "code",
   "source": [
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model=DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased',num_labels=len(emotions))\n",
    "model.to(device)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./emotion_results',  # Directory to save model checkpoints\n",
    "    num_train_epochs=3,              # Number of times to run through the entire training set (Adjust if needed)\n",
    "    per_device_train_batch_size=16,  # Training batch size (Adjust if you run out of GPU memory)\n",
    "    per_device_eval_batch_size=64,   # Evaluation batch size (can be larger than training batch size)\n",
    "    learning_rate=2e-5,\n",
    "    warmup_steps=500,                # Learning rate scheduler warm-up steps\n",
    "    weight_decay=0.01,               # L2 regularization\n",
    "    logging_dir='./emotion_logs',    # Directory for logs\n",
    "    logging_steps=100,               # Log training status every 100 steps\n",
    "    save_strategy=\"epoch\",     # Save best model version after each epoch\n",
    "    eval_strategy=\"epoch\",     # Run evaluation on the validation set after every epoch\n",
    "    load_best_model_at_end=True,     # Save the model that performs best on the validation set\n",
    "    fp16=True,                       # Enables faster 16-bit precision training (requires GPU)\n",
    "    report_to=\"none\"\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HcpxFjEMaO8q",
    "outputId": "87d2221d-ed30-4cb9-d09b-2d97d56ede8b",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:29:02.445783Z",
     "start_time": "2025-11-21T07:29:01.488142Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculating the performance metrics"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
    "num_emotions=len(emotions)\n",
    "def compute_metrics(p):\n",
    "    \"\"\"\n",
    "    Computes accuracy, weighted F1, and per-class precision (to check specific emotions).\n",
    "    \"\"\"\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(p.label_ids, preds, average='weighted', zero_division=0)\n",
    "    acc = accuracy_score(p.label_ids, preds)\n",
    "    class_metrics = precision_recall_fscore_support(p.label_ids, preds, average=None, labels=range(num_emotions), zero_division=0)\n",
    "    class_precision = class_metrics[0]\n",
    "    precision_by_class = {emotions[i]: class_precision[i] for i in range(num_emotions)}\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        **{f'precision_{k}': v for k, v in precision_by_class.items()}, # Adds individual precision scores\n",
    "    }"
   ],
   "metadata": {
    "id": "6mDlX9jlltgW",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:29:02.469003Z",
     "start_time": "2025-11-21T07:29:02.465664Z"
    }
   },
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Initializing a trainer object from Hugging Face Trainer class"
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "print(\"Hugging Face Trainer initialized successfully.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u5suU4meqLyr",
    "outputId": "5e4bfc7c-f382-4ba5-a239-15bc03eb35a1",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:29:02.589295Z",
     "start_time": "2025-11-21T07:29:02.473978Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Face Trainer initialized successfully.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Training the model"
  },
  {
   "cell_type": "code",
   "source": [
    "trainer.train()\n",
    "final_results=trainer.evaluate(test_dataset)\n",
    "print(final_results)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "j-Ls70fvsSAV",
    "outputId": "74c2f9a0-bbb6-4410-e06a-8fd432b81037",
    "ExecuteTime": {
     "end_time": "2025-11-21T07:42:38.504329Z",
     "start_time": "2025-11-21T07:29:02.600805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15954' max='15954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15954/15954 13:30, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision Fun</th>\n",
       "      <th>Precision Surprise</th>\n",
       "      <th>Precision Neutral</th>\n",
       "      <th>Precision Enthusiasm</th>\n",
       "      <th>Precision Happiness</th>\n",
       "      <th>Precision Hate</th>\n",
       "      <th>Precision Sadness</th>\n",
       "      <th>Precision Empty</th>\n",
       "      <th>Precision Love</th>\n",
       "      <th>Precision Relief</th>\n",
       "      <th>Precision Anger</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.349200</td>\n",
       "      <td>0.367162</td>\n",
       "      <td>0.885096</td>\n",
       "      <td>0.888268</td>\n",
       "      <td>0.894924</td>\n",
       "      <td>0.885096</td>\n",
       "      <td>0.922581</td>\n",
       "      <td>0.755082</td>\n",
       "      <td>0.963037</td>\n",
       "      <td>0.998924</td>\n",
       "      <td>0.729825</td>\n",
       "      <td>0.967809</td>\n",
       "      <td>0.678454</td>\n",
       "      <td>0.992661</td>\n",
       "      <td>0.973849</td>\n",
       "      <td>0.978587</td>\n",
       "      <td>0.919028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.282900</td>\n",
       "      <td>0.354562</td>\n",
       "      <td>0.889610</td>\n",
       "      <td>0.891328</td>\n",
       "      <td>0.894542</td>\n",
       "      <td>0.889610</td>\n",
       "      <td>0.894949</td>\n",
       "      <td>0.771513</td>\n",
       "      <td>0.968844</td>\n",
       "      <td>0.974869</td>\n",
       "      <td>0.784091</td>\n",
       "      <td>0.971846</td>\n",
       "      <td>0.708262</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.947528</td>\n",
       "      <td>0.963427</td>\n",
       "      <td>0.921986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.213400</td>\n",
       "      <td>0.388078</td>\n",
       "      <td>0.889046</td>\n",
       "      <td>0.890193</td>\n",
       "      <td>0.891950</td>\n",
       "      <td>0.889046</td>\n",
       "      <td>0.887663</td>\n",
       "      <td>0.754302</td>\n",
       "      <td>0.975758</td>\n",
       "      <td>0.960825</td>\n",
       "      <td>0.802927</td>\n",
       "      <td>0.963768</td>\n",
       "      <td>0.735971</td>\n",
       "      <td>0.927242</td>\n",
       "      <td>0.946573</td>\n",
       "      <td>0.949949</td>\n",
       "      <td>0.919355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='167' max='167' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [167/167 00:04]\n",
       "    </div>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3523584008216858, 'eval_accuracy': 0.8872696502444528, 'eval_f1': 0.889136728171582, 'eval_precision': 0.8925220076432021, 'eval_recall': 0.8872696502444528, 'eval_precision_fun': 0.8941058941058941, 'eval_precision_surprise': 0.7566793893129771, 'eval_precision_neutral': 0.9684106614017769, 'eval_precision_enthusiasm': 0.9741735537190083, 'eval_precision_happiness': 0.7838364167478091, 'eval_precision_hate': 0.9736842105263158, 'eval_precision_sadness': 0.6974935177182369, 'eval_precision_empty': 0.9650959860383944, 'eval_precision_love': 0.9491869918699187, 'eval_precision_relief': 0.9619047619047619, 'eval_precision_anger': 0.9195876288659793, 'eval_runtime': 4.5391, 'eval_samples_per_second': 2343.214, 'eval_steps_per_second': 36.792, 'epoch': 3.0}\n"
     ]
    }
   ],
   "execution_count": 11
  }
 ]
}
